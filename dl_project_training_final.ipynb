{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dl_project_beta0_5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUMC8iE55cLO",
        "outputId": "818141be-4cb1-4916-882f-c873e118d2e0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E97F-7kX5j-c",
        "outputId": "959fac47-dce4-452e-88ab-d3c40d48efba"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import sys\n",
        "import torch.optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "import time\n",
        "import csv\n",
        "import os\n",
        "from os import path\n",
        "\n",
        "batch_size = 64\n",
        "n_workers = 2\n",
        "cuda = torch.cuda.is_available()\n",
        "print(cuda, sys.version)\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True 3.7.10 (default, Feb 20 2021, 21:17:23) \n",
            "[GCC 7.5.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9mR4llt6Kjz",
        "outputId": "0fa661ff-6bbe-4ba3-c21f-55ca0306084e"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 8651875132216150705, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 15505193728\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 8219768358649371244\n",
              " physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzi_KlMu8biX"
      },
      "source": [
        "!cp /content/gdrive/MyDrive/dl/project/unique-142p.zip /content\n",
        "!cp /content/gdrive/MyDrive/dl/project/scene-change.csv /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnAJBgG99z5e"
      },
      "source": [
        "!unzip /content/unique-142p.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjAXsQxr6VFG"
      },
      "source": [
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, main_dir, transform):\n",
        "        self.main_dir = main_dir\n",
        "        self.transform = transform\n",
        "        imgs = os.listdir(main_dir)\n",
        "        self.total_imgs = []\n",
        "        for i in imgs:\n",
        "          if 'frame' in i and int(i[6:-4]) > 25947:\n",
        "            self.total_imgs.append(i) \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.total_imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
        "        image = Image.open(img_loc).convert(\"RGB\")\n",
        "        tensor_image = self.transform(image)\n",
        "        return tensor_image\n",
        "\n",
        "class ValDataset(Dataset):\n",
        "    def __init__(self, main_dir, transform):\n",
        "        self.main_dir = main_dir\n",
        "        self.transform = transform\n",
        "        imgs = os.listdir(main_dir)\n",
        "        self.total_imgs = []\n",
        "        for i in imgs:\n",
        "          if 'frame' in i and int(i[6:-4]) <= 25947:\n",
        "            self.total_imgs.append(i) \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.total_imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
        "        image = Image.open(img_loc).convert(\"RGB\")\n",
        "        tensor_image = self.transform(image)\n",
        "        return tensor_image\n",
        "\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize((64, 64)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taKya1tdEDhC"
      },
      "source": [
        "train_dataset = TrainDataset(\"unique-142p\", transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=n_workers, pin_memory=False, drop_last=True)\n",
        "\n",
        "val_dataset = ValDataset(\"unique-142p\", transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=n_workers, pin_memory=False, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3G7W3lXEWEQ"
      },
      "source": [
        "def reconstruction_loss(x, x_recon, distribution):\n",
        "    batch_size = x.size(0)\n",
        "    assert batch_size != 0\n",
        "\n",
        "    if distribution == 'bernoulli':\n",
        "        recon_loss = F.binary_cross_entropy_with_logits(x_recon, x, size_average=False).div(batch_size)\n",
        "    elif distribution == 'gaussian':\n",
        "        x_recon = F.sigmoid(x_recon)\n",
        "        recon_loss = F.mse_loss(x_recon, x, size_average=False).div(batch_size)\n",
        "    else:\n",
        "        recon_loss = None\n",
        "\n",
        "    return recon_loss\n",
        "\n",
        "\n",
        "def kl_divergence(mu, logvar):\n",
        "    batch_size = mu.size(0)\n",
        "    assert batch_size != 0\n",
        "    if mu.data.ndimension() == 4:\n",
        "        mu = mu.view(mu.size(0), mu.size(1))\n",
        "    if logvar.data.ndimension() == 4:\n",
        "        logvar = logvar.view(logvar.size(0), logvar.size(1))\n",
        "\n",
        "    klds = -0.5*(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    total_kld = klds.sum(1).mean(0, True)\n",
        "    dimension_wise_kld = klds.mean(0)\n",
        "    mean_kld = klds.mean(1).mean(0, True)\n",
        "\n",
        "    return total_kld, dimension_wise_kld, mean_kld"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGzMm7pcEXrD"
      },
      "source": [
        "def reparametrize(mu, logvar):\n",
        "    std = logvar.div(2).exp()\n",
        "    eps = Variable(std.data.new(std.size()).normal_())\n",
        "    return mu + std*eps\n",
        "\n",
        "\n",
        "class View(nn.Module):\n",
        "    def __init__(self, size):\n",
        "        super(View, self).__init__()\n",
        "        self.size = size\n",
        "\n",
        "    def forward(self, tensor):\n",
        "        return tensor.view(self.size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEIMQLwKEiYs"
      },
      "source": [
        "class BetaVAE_H(nn.Module):\n",
        "    \"\"\"Model proposed in original beta-VAE paper(Higgins et al, ICLR, 2017).\"\"\"\n",
        "\n",
        "    def __init__(self, z_dim=10, nc=3):\n",
        "        super(BetaVAE_H, self).__init__()\n",
        "        self.z_dim = z_dim\n",
        "        self.nc = nc\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(nc, 32, 4, 2, 1),          # B,  32, 32, 32\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(32, 32, 4, 2, 1),          # B,  32, 16, 16\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(32, 64, 4, 2, 1),          # B,  64,  8,  8\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(64, 64, 4, 2, 1),          # B,  64,  4,  4\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(64, 256, 4, 1),            # B, 256,  1,  1\n",
        "            nn.ReLU(True),\n",
        "            View((-1, 256*1*1)),                 # B, 256\n",
        "            nn.Linear(256, z_dim*2),             # B, z_dim*2\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(z_dim, 256),               # B, 256\n",
        "            View((-1, 256, 1, 1)),               # B, 256,  1,  1\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(256, 64, 4),      # B,  64,  4,  4\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(64, 64, 4, 2, 1), # B,  64,  8,  8\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(64, 32, 4, 2, 1), # B,  32, 16, 16\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(32, 32, 4, 2, 1), # B,  32, 32, 32\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(32, nc, 4, 2, 1),  # B, nc, 64, 64\n",
        "        )\n",
        "\n",
        "        self.weight_init()\n",
        "\n",
        "    def weight_init(self):\n",
        "        for block in self._modules:\n",
        "            for m in self._modules[block]:\n",
        "                kaiming_init(m)\n",
        "\n",
        "    def forward(self, x, train=True):\n",
        "        distributions = self.encoder(x)\n",
        "        mu = distributions[:, :self.z_dim]\n",
        "        logvar = distributions[:, self.z_dim:]\n",
        "        z = reparametrize(mu, logvar)\n",
        "        x_recon = self.decoder(z)\n",
        "        if not train:\n",
        "          return x_recon, z\n",
        "          \n",
        "        return x_recon, mu, logvar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i63TF1lIEud3"
      },
      "source": [
        "def kaiming_init(m):\n",
        "    if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
        "        init.kaiming_normal_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.fill_(0)\n",
        "    elif isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d)):\n",
        "        m.weight.data.fill_(1)\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.fill_(0)\n",
        "\n",
        "\n",
        "def normal_init(m, mean, std):\n",
        "    if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
        "        m.weight.data.normal_(mean, std)\n",
        "        if m.bias.data is not None:\n",
        "            m.bias.data.zero_()\n",
        "    elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\n",
        "        m.weight.data.fill_(1)\n",
        "        if m.bias.data is not None:\n",
        "            m.bias.data.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GWvySflE5JC",
        "outputId": "7fc78446-bb15-4a7e-9728-d6614bc75e93"
      },
      "source": [
        "model = BetaVAE_H()\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BetaVAE_H(\n",
            "  (encoder): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(64, 256, kernel_size=(4, 4), stride=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): View()\n",
            "    (11): Linear(in_features=256, out_features=20, bias=True)\n",
            "  )\n",
            "  (decoder): Sequential(\n",
            "    (0): Linear(in_features=10, out_features=256, bias=True)\n",
            "    (1): View()\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(1, 1))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (10): ReLU(inplace=True)\n",
            "    (11): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k62FplYRFFTl"
      },
      "source": [
        "def train(model, optimiser, dataloader, beta):\n",
        "    model.train()\n",
        "    # self.C_max = Variable(cuda(torch.FloatTensor([self.C_max]), self.use_cuda))\n",
        "    rl = 0\n",
        "    bl = 0\n",
        "    kl = 0\n",
        "    trl = []\n",
        "    tbl = []\n",
        "    tkl = []\n",
        "    for i, x in enumerate(dataloader):\n",
        "        x = x.cuda()\n",
        "        x_recon, mu, logvar = model(x)\n",
        "        recon_loss = reconstruction_loss(x, x_recon, 'gaussian')\n",
        "        total_kld, dim_wise_kld, mean_kld = kl_divergence(mu, logvar)\n",
        "\n",
        "        beta_vae_loss = recon_loss + beta*total_kld\n",
        "        \n",
        "        optimiser.zero_grad()\n",
        "        beta_vae_loss.backward()\n",
        "        optimiser.step()\n",
        "        \n",
        "        rl+=recon_loss.item()\n",
        "        kl+=total_kld.item()\n",
        "        bl+=beta_vae_loss.item()\n",
        "\n",
        "        if i % 20 == 0:\n",
        "            print('[{}] recon_loss:{:.3f} total_kld:{:.3f} mean_kld:{:.3f} beta_vae_loss:{:.3f}'.format(\n",
        "                i, recon_loss.item(), total_kld.item(), mean_kld.item(), beta_vae_loss.item()))\n",
        "\n",
        "            trl.append(recon_loss.item())\n",
        "            tkl.append(total_kld.item())\n",
        "            tbl.append(beta_vae_loss.item())\n",
        "\n",
        "    return rl/len(dataloader), bl/len(dataloader), kl/len(dataloader), trl, tbl, tkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlRl1BigxczT"
      },
      "source": [
        "def val(model, optimiser, dataloader, beta):\n",
        "    model.eval()\n",
        "    rl = 0\n",
        "    bl = 0\n",
        "    kl = 0\n",
        "    trl = []\n",
        "    tbl = []\n",
        "    tkl = []\n",
        "    for i, x in enumerate(dataloader):\n",
        "        x = x.cuda()\n",
        "        x_recon, mu, logvar = model(x)\n",
        "        recon_loss = reconstruction_loss(x, x_recon, 'gaussian')\n",
        "        total_kld, dim_wise_kld, mean_kld = kl_divergence(mu, logvar)\n",
        "\n",
        "        beta_vae_loss = recon_loss + beta*total_kld\n",
        "        \n",
        "        rl+=recon_loss.item()\n",
        "        kl+=total_kld.item()\n",
        "        bl+=beta_vae_loss.item()\n",
        "\n",
        "        if i % 20 == 0:\n",
        "            print('[{}] recon_loss:{:.3f} total_kld:{:.3f} mean_kld:{:.3f} beta_vae_loss:{:.3f}'.format(\n",
        "                i, recon_loss.item(), total_kld.item(), mean_kld.item(), beta_vae_loss.item()))\n",
        "\n",
        "            trl.append(recon_loss.item())\n",
        "            tkl.append(total_kld.item())\n",
        "            tbl.append(beta_vae_loss.item())\n",
        "\n",
        "    return rl/len(dataloader), bl/len(dataloader), kl/len(dataloader), trl, tbl, tkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKkgM1XZFwlX"
      },
      "source": [
        "model.cuda()\n",
        "\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimiser, step_size=100, gamma=0.5)\n",
        "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimiser, mode=\"min\", factor=0.3, patience=1, verbose=True)\n",
        "epochs = 100\n",
        "betas = [0.25, 0.5, 1, 2, 4]\n",
        "\n",
        "\n",
        "TRL, TBL, TKL, RL, BL, KL = [], [], [], [], [], []\n",
        "val_TRL, val_TBL, val_TKL, val_RL, val_BL, val_KL = [], [], [], [], [], []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBPT24PFH_1t",
        "outputId": "a16a1c6f-cfd6-420c-f5b6-27854ee5e545"
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "id": "v4-rLlzZ00JD",
        "outputId": "4c235be2-e8e2-4c83-a69d-7dd6b9327fa7"
      },
      "source": [
        "loss_df = pd.DataFrame([], columns=['Epoch', 'Beta', 'Train Rec_Loss', 'Train KL_Loss', 'Train Beta_Loss','Val Rec_Loss', 'Val KL_Loss', 'Val Beta_Loss'])\n",
        "loss_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Epoch</th>\n",
              "      <th>Beta</th>\n",
              "      <th>Train Rec_Loss</th>\n",
              "      <th>Train KL_Loss</th>\n",
              "      <th>Train Beta_Loss</th>\n",
              "      <th>Val Rec_Loss</th>\n",
              "      <th>Val KL_Loss</th>\n",
              "      <th>Val Beta_Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Epoch, Beta, Train Rec_Loss, Train KL_Loss, Train Beta_Loss, Val Rec_Loss, Val KL_Loss, Val Beta_Loss]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFTCg2PmGrAr"
      },
      "source": [
        "for beta in betas:\n",
        "    model_no = beta\n",
        "    TRL, TBL, TKL, RL, BL, KL = [], [], [], [], [], []\n",
        "    val_TRL, val_TBL, val_TKL, val_RL, val_BL, val_KL = [], [], [], [], [], []\n",
        "\n",
        "    for i in range(epochs):\n",
        "        print(scheduler.get_last_lr())\n",
        "        \n",
        "        print(\"Epoch\", i)\n",
        "        start = time.time()\n",
        "        rl, bl, kl, trl, tbl, tkl = train(model, optimiser, train_loader, beta)\n",
        "        val_rl, val_bl, val_kl, val_trl, val_tbl, val_tkl = val(model, optimiser, val_loader, beta)\n",
        "        print(\"RL:\", rl, \"BL:\", bl, \"KL:\", kl)\n",
        "        print(\"val_RL:\", val_rl, \"val_BL:\", val_bl, \"val_KL:\", val_kl)\n",
        "        print(\"Train time:\", time.time()-start)\n",
        "        \n",
        "        TRL += trl\n",
        "        TBL += tbl\n",
        "        TKL += tkl\n",
        "        RL.append(rl)\n",
        "        BL.append(bl)\n",
        "        KL.append(kl)\n",
        "\n",
        "        val_TRL += val_trl\n",
        "        val_TBL += val_tbl\n",
        "        val_TKL += val_tkl\n",
        "        val_RL.append(val_rl)\n",
        "        val_BL.append(val_bl)\n",
        "        val_KL.append(val_kl)\n",
        "        \n",
        "        # scheduler.step()\n",
        "        loss_df = loss_df.append(pd.DataFrame([[i, beta, rl, kl, bl, val_rl, val_kl, val_bl]], columns=['Epoch', 'Beta', 'Train Rec_Loss', 'Train KL_Loss', 'Train Beta_Loss','Val Rec_Loss', 'Val KL_Loss', 'Val Beta_Loss']))\n",
        "        \n",
        "        torch.save({\n",
        "                    'epoch': i,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimiser_state_dict': optimiser.state_dict(),\n",
        "                    'scheduler_state_dict': scheduler.state_dict(),\n",
        "                    'trl': TRL,\n",
        "                    'tbl': TBL,\n",
        "                    'tkl': TKL,\n",
        "                    'rl': RL,\n",
        "                    'bl': BL,\n",
        "                    'kl': KL,\n",
        "                    'val_trl': val_TRL,\n",
        "                    'val_tbl': val_TBL,\n",
        "                    'val_tkl': val_TKL,\n",
        "                    'val_rl': val_RL,\n",
        "                    'val_bl': val_BL,\n",
        "                    'val_kl': val_KL,\n",
        "                    }, 'gdrive/MyDrive/dl/project/new_model/new_model_' + str(model_no) + '_' + str(i))\n",
        "\n",
        "loss_df.to_csv('results_05_4_.csv', index=False)\n",
        "!cp results_05_4_.csv /content/gdrive/MyDrive/dl/project/new_model/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}